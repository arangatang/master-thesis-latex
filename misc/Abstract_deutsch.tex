Zeitreihenprognosen sind ein wichtiges Werkzeug für Unternehmen, Organisationen und Regierungen, da sie es ihnen ermöglichen, besser zu planen und sich an die Zukunft anzupassen. In der Vergangenheit hat sich gezeigt, dass Deep-Learning-basierte Prognosemodelle im Vergleich zu klassischen Ansätzen wie ARIMA, ETS und Theta eine schlechte Leistung aufweisen. In den letzten Jahren wurden mehrere neue Deep-Learning-basierte Methoden vorgeschlagen und daher ist es wichtig, diese zu evaluieren. In dieser Arbeit werden mehrere aktuelle Prognosemodelle und Methoden untersucht, um faire, genaue und reproduzierbare Vergleiche durchführen zu können. Da sich die Forschung im Bereich des maschinellen Lernens derzeit in einer Reproduzierbarkeitskrise befindet, liegt ein besonderer Schwerpunkt auf der Identifizierung von Methoden zur Erzeugung technisch, statistisch und konzeptionell reproduzierbarer Ergebnisse.

In dieser Arbeit wird auch Crayon vorgestellt, eine Open-Source-Benchmarking-Suite für faire, genaue und reproduzierbare Vergleiche von Vorhersagemethoden. Crayon nutzt Verteilungen von Fehlermetriken für seine Benchmarks und stellt Algorithmen durch eine neuartige Aggregationsmethode von Fehlerverteilungen gegeneinander. Diese Methode, genannt RMSE4D, ist auf jede Fehlermetrik-Verteilung anwendbar und bewertet Algorithmen, die konsistente Prognosen erzeugen, höher. Darüber hinaus wird in Crayon ein auf dem Kolmogorov-Smirnov-2-Stichprobentest basierendes Tooling eingesetzt, um die statistische Reproduzierbarkeit von Benchmarks zu ermöglichen, und sein praktischer Nutzen wird durch den Schutz eines Prognoserahmens vor Genauigkeitsregressionen demonstriert. Crayon wird in dieser Arbeit zum Benchmarking von 13 modernen Prognosealgorithmen auf vier populären öffentlichen Datensätzen mit komplementären Eigenschaften in Bezug auf Trend und Saisonalität verwendet. Die wichtigsten Ergebnisse dieses Vergleichs sind, dass DeepAR, Transformer und das N-BEATS Ensamble die leistungsfähigsten Modelle für drei der Datensätze sind, dass aber naive und klassische Ansätze wie Theta die leistungsfähigsten Algorithmen für Datensätze mit hohem Trend sind.